# Data 

```{r, include=FALSE, warning=FALSE}
library(tidyquant)
library(tidyverse)
library(fpp3)
library(ggplot2)
library(ggridges)
library(scales)
```

## Sources

```{r}
start_date <- "2016-01-01"
end_date <- "2020-12-31"
```


```{r}
# Data Set 1
tickers_1 = c("^GSPC", "^N225", "000001.SS")
data_reg <- tq_get(tickers_1, 
                   get = "stock.prices", 
                   from = start_date, 
                   to = end_date)
```

```{r}
# Data Set 2
# order: IT, Health Care, Financials, Consumer Discretionary, Communication Services
#        Industrial, Consumer Staples, Energy, Utilities, Real Estate, Materials
tickers_2 = c("^SP500-45", "^SP500-35", "^SP500-40", 
              "^SP500-25", "^SP500-50", "^SP500-20", 
              "^SP500-30", "^GSPE", "^SP500-55", 
              "^SP500-60", "^SP500-15")
data_sec <- tq_get(tickers_2, 
                   get = "stock.prices", 
                   from = start_date, 
                   to = end_date)
```

## Cleaning / transformation

#### Part 1

```{r}
# Change tickers to names
data_reg |> 
  mutate(symbol = 
           case_when(
             (symbol == "^GSPC") ~ "S&P_500", 
             (symbol == "^N225") ~ "Nikkei_225", 
             TRUE ~ "SSE_Composite"
           )) |>
  drop_na() -> data_reg
```

```{r}
# adjust to USD
jpy_usd_avg <- 111.1924
chy_usd_avg <- 6.874
data_reg |> 
  mutate(exg_rate = 
           case_when(
             (symbol == "Nikkei_225") ~ jpy_usd_avg, 
             (symbol == "SSE_Composite") ~ chy_usd_avg, 
             TRUE ~ 1
           )) |>
  mutate(across(c(open, high, low, close, adjusted), ~ .x / exg_rate)) -> data_reg
```

```{r}
# Standardize (take log) - for boxplot
data_reg |>
  mutate(log_price = log(adjusted)) |>
  select(date, symbol, log_price) -> adj_price_std
```

```{r}
# Change tickers to sector names
data_sec |>
  mutate(sector = 
           case_when(
             (symbol == "^SP500-45") ~ "Information Technology", 
             (symbol == "^SP500-35") ~ "Health Care", 
             (symbol == "^SP500-40") ~ "Financials", 
             (symbol == "^SP500-25") ~ "Consumer Discretionary", 
             (symbol == "^SP500-50") ~ "Communication Services", 
             (symbol == "^SP500-20") ~ "Industrial", 
             (symbol == "^SP500-30") ~ "Consumer Staples", 
             (symbol == "^GSPE") ~ "Energy", 
             (symbol == "^SP500-55") ~ "Utilities", 
             (symbol == "^SP500-60") ~ "Real Estate", 
             TRUE ~ "Materials"
           )) |>
  drop_na() -> data_sec
```


#### Part 2

## Missing value analysis

(mention gap between dates - weekends and holidays)
```{r}
summary(data_sec)
```

```{r}
#md.pattern(data_sec)
colSums(is.na(data_sec)) %>%  
  sort(decreasing = TRUE)
```
From this we know that there are 152 days where we miss all column values except for date and the symbol.
This might be due to holidays, and it's not feasible to impute values. We will drop these rows.

```{r}
data_sec <- data_sec %>% drop_na()

colSums(is.na(data_sec)) %>%  
  sort(decreasing = TRUE)
```
```{r}
data_d3 = data_reg |> filter(symbol == "S&P_500")
data_d3
```
```{r}
write.csv(data_d3, "data/sp500.csv")
```

